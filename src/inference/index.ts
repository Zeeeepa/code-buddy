/**
 * Inference Module
 *
 * Tools for optimizing local LLM inference:
 * - KV-Cache configuration and management
 * - Speculative decoding for faster generation
 */

export * from './kv-cache-config.js';
export * from './speculative-decoding.js';
